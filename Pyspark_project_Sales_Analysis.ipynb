{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f3de95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d03c059e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark\\\\spark-3.5.0-bin-hadoop3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ba45dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "378d9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime, date\n",
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType,DateType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b0e9003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create SparkSession\n",
    "spark = SparkSession.\\\n",
    "builder.\\\n",
    "appName(\"sparksql1\").\\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bee1fad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales='C:/Users/DELL/Documents/pyspark/sales.csv.txt'\n",
    "menu='C:/Users/DELL/Documents/pyspark/menu.csv.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "327a9847",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema=StructType([\n",
    "    StructField(\"product_id\",IntegerType(),True),\n",
    "    StructField(\"customer_id\",StringType(),True),\n",
    "    StructField(\"order_date\",DateType(),True),\n",
    "    StructField(\"location\",StringType(),True),\n",
    "    StructField(\"source_order\",StringType(),True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a171e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = spark.read.csv(\"sales.csv.txt\",sep = \",\",schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cf493f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+--------+------------+\n",
      "|product_id|customer_id|order_date|location|source_order|\n",
      "+----------+-----------+----------+--------+------------+\n",
      "|         1|          A|2023-01-01|   India|      Swiggy|\n",
      "|         2|          A|2022-01-01|   India|      Swiggy|\n",
      "|         2|          A|2023-01-07|   India|      Swiggy|\n",
      "+----------+-----------+----------+--------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec1fc8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+--------+------------+----------+-----------+-------------+\n",
      "|product_id|customer_id|order_date|location|source_order|order_year|order_month|order_quarter|\n",
      "+----------+-----------+----------+--------+------------+----------+-----------+-------------+\n",
      "|         1|          A|2023-01-01|   India|      Swiggy|      2023|          1|            1|\n",
      "|         2|          A|2022-01-01|   India|      Swiggy|      2022|          1|            1|\n",
      "|         2|          A|2023-01-07|   India|      Swiggy|      2023|          1|            1|\n",
      "|         3|          A|2023-01-10|   India|  Restaurant|      2023|          1|            1|\n",
      "|         3|          A|2022-01-11|   India|      Swiggy|      2022|          1|            1|\n",
      "|         3|          A|2023-01-11|   India|  Restaurant|      2023|          1|            1|\n",
      "|         2|          B|2022-02-01|   India|      Swiggy|      2022|          2|            1|\n",
      "|         2|          B|2023-01-02|   India|      Swiggy|      2023|          1|            1|\n",
      "|         1|          B|2023-01-04|   India|  Restaurant|      2023|          1|            1|\n",
      "|         1|          B|2023-02-11|   India|      Swiggy|      2023|          2|            1|\n",
      "|         3|          B|2023-01-16|   India|      zomato|      2023|          1|            1|\n",
      "|         3|          B|2022-02-01|   India|      zomato|      2022|          2|            1|\n",
      "|         3|          C|2023-01-01|   India|      zomato|      2023|          1|            1|\n",
      "|         1|          C|2023-01-01|      UK|      Swiggy|      2023|          1|            1|\n",
      "|         6|          C|2022-01-07|      UK|      zomato|      2022|          1|            1|\n",
      "|         3|          D|2023-02-16|      UK|  Restaurant|      2023|          2|            1|\n",
      "|         5|          D|2022-02-01|      UK|      zomato|      2022|          2|            1|\n",
      "|         3|          E|2023-02-01|      UK|  Restaurant|      2023|          2|            1|\n",
      "|         4|          E|2023-02-01|      UK|      Swiggy|      2023|          2|            1|\n",
      "|         4|          E|2023-02-07|      UK|  Restaurant|      2023|          2|            1|\n",
      "+----------+-----------+----------+--------+------------+----------+-----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# deriving year,month,quarter\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "data_1= data_1.select(\n",
    "    '*',\n",
    "    F.year('order_date').alias('order_year'),\n",
    "    F.month('order_date').alias('order_month'),\n",
    "    F.quarter('order_date').alias('order_quarter')\n",
    ")\n",
    "data_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "329bc9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----+\n",
      "|product_id|product_name|price|\n",
      "+----------+------------+-----+\n",
      "|         1|       PIZZA|  100|\n",
      "|         2|     Chowmin|  150|\n",
      "|         3|    sandwich|  120|\n",
      "|         4|        Dosa|  110|\n",
      "|         5|     Biryani|   80|\n",
      "+----------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using menu dataframe\n",
    "schema=StructType([\n",
    "    StructField(\"product_id\",IntegerType(),True),\n",
    "    StructField(\"product_name\",StringType(),True),\n",
    "    StructField(\"price\",StringType(),True)\n",
    "])\n",
    "data_2 = spark.read.csv(\"menu.csv.txt\",sep = \",\",schema = schema)\n",
    "data_2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "533bce02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|customer_id|sum(price)|\n",
      "+-----------+----------+\n",
      "|          A|    4260.0|\n",
      "|          B|    4440.0|\n",
      "|          C|    2400.0|\n",
      "|          D|    1200.0|\n",
      "|          E|    2040.0|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total Amount spent by each customer\n",
    "total_amount_spent=(data_1.join(data_2,\"product_id\").\\\n",
    "                    groupBy(\"customer_id\").\\\n",
    "                    agg({'price':'sum'}).\\\n",
    "                    orderBy(\"customer_id\")\n",
    "                   )\n",
    "total_amount_spent.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afc6d724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|order_month|sum(price)|\n",
      "+-----------+----------+\n",
      "|          1|    2960.0|\n",
      "|          2|    2730.0|\n",
      "|          3|     910.0|\n",
      "|          5|    2960.0|\n",
      "|          6|    2960.0|\n",
      "|          7|     910.0|\n",
      "|         11|     910.0|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total amount of sales in each month\n",
    "df_1=(data_1.join(data_2,\"product_id\").\\\n",
    "                    groupBy(\"order_month\").\\\n",
    "                    agg({'price':'sum'}).\\\n",
    "                    orderBy(\"order_month\")\n",
    "                   )\n",
    "df_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0782690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|order_year|sum(price)|\n",
      "+----------+----------+\n",
      "|      2022|    4350.0|\n",
      "|      2023|    9990.0|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Yearly Sales\n",
    "df_2=(data_1.join(data_2,\"product_id\").\\\n",
    "                    groupBy(\"order_year\").\\\n",
    "                    agg({'price':'sum'}).\\\n",
    "                    orderBy(\"order_year\")\n",
    "                   )\n",
    "df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90c66d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|order_quarter|sum(price)|\n",
      "+-------------+----------+\n",
      "|            1|    6600.0|\n",
      "|            2|    5920.0|\n",
      "|            3|     910.0|\n",
      "|            4|     910.0|\n",
      "+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quaterly Sales\n",
    "df_3=(data_1.join(data_2,\"product_id\").\\\n",
    "                    groupBy(\"order_quarter\").\\\n",
    "                    agg({'price':'sum'}).\\\n",
    "                    orderBy(\"order_quarter\")\n",
    "                   )\n",
    "df_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0fe07d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+\n",
      "|product_name|product_count|\n",
      "+------------+-------------+\n",
      "|    sandwich|           48|\n",
      "|     Chowmin|           24|\n",
      "|       PIZZA|           21|\n",
      "|        Dosa|           12|\n",
      "|     Biryani|            6|\n",
      "|       Pasta|            6|\n",
      "+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many times each product has been purchased\n",
    "from pyspark.sql.functions import count\n",
    "df_4=(data_1.join(data_2,\"product_id\").\\\n",
    "                    groupBy(\"product_id\",\"product_name\").\\\n",
    "                    agg(count(\"product_id\").alias(\"product_count\")).\\\n",
    "                    orderBy(\"product_count\",ascending=0).\\\n",
    "                    drop(\"product_id\")\n",
    "                   )\n",
    "df_4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f2a1b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+\n",
      "|product_name|product_count|\n",
      "+------------+-------------+\n",
      "|    sandwich|           48|\n",
      "|     Chowmin|           24|\n",
      "|       PIZZA|           21|\n",
      "|        Dosa|           12|\n",
      "|     Biryani|            6|\n",
      "+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Top 5 ordered items\n",
    "df_4=(data_1.join(data_2,\"product_id\").\\\n",
    "                    groupBy(\"product_id\",\"product_name\").\\\n",
    "                    agg(count(\"product_id\").alias(\"product_count\")).\\\n",
    "                    orderBy(\"product_count\",ascending=0).\\\n",
    "                    drop(\"product_id\").\\\n",
    "                    limit(5)\n",
    "                   )\n",
    "df_4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "060a6194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+\n",
      "|product_name|product_count|\n",
      "+------------+-------------+\n",
      "|    sandwich|           48|\n",
      "+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Top ordered item\n",
    "df_4=(data_1.join(data_2,\"product_id\").\\\n",
    "                    groupBy(\"product_id\",\"product_name\").\\\n",
    "                    agg(count(\"product_id\").alias(\"product_count\")).\\\n",
    "                    orderBy(\"product_count\",ascending=0).\\\n",
    "                    drop(\"product_id\").\\\n",
    "                    limit(1)\n",
    "                   )\n",
    "df_4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "693efd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|customer_id|Frequency_of_visit|\n",
      "+-----------+------------------+\n",
      "|          E|                 5|\n",
      "|          B|                 6|\n",
      "|          D|                 1|\n",
      "|          C|                 3|\n",
      "|          A|                 6|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Frequency of customer of vising the restaurant\n",
    "from pyspark.sql.functions import countDistinct\n",
    "df_5=(data_1.filter(data_1.source_order=='Restaurant').\\\n",
    "                   groupBy(\"customer_id\").\\\n",
    "                   agg(countDistinct(\"order_date\").alias(\"Frequency_of_visit\"))\n",
    "                   )\n",
    "df_5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "471e025c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|location|sum(price)|\n",
      "+--------+----------+\n",
      "|   India|    4860.0|\n",
      "|     USA|    2460.0|\n",
      "|      UK|    7020.0|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total sales by each country\n",
    "df_6=(data_1.join(data_2,\"product_id\").\\\n",
    "                    groupBy(\"location\").\\\n",
    "                    agg({'price':'sum'})\n",
    "                   )\n",
    "df_6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d317251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|source_order|sum(price)|\n",
      "+------------+----------+\n",
      "|      zomato|    4920.0|\n",
      "|      Swiggy|    6330.0|\n",
      "|  Restaurant|    3090.0|\n",
      "+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total sales by order source\n",
    "df_7=(data_1.join(data_2,\"product_id\").\\\n",
    "                    groupBy(\"source_order\").\\\n",
    "                    agg({'price':'sum'})\n",
    "                   )\n",
    "df_7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c862d4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
